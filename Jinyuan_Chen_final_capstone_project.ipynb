{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the elder health issue, fall is a serious public health problem and possibly life-threatening for people in fall risk groups. It is one of the most important turning points which not only the manifestation of diseases but also triggers other diseases. Thus, detecting falling and tracking movement helps researchers better understand the information before elder falls. Thereby, researchers can build a warning system to warn people around or send message to relatives in time.\n",
    "Özdemir et al develop an automated fall detection system with wearable motion sensor units fitted to the subjects' body at six different positions. Each unit comprises three triaxial devices (accelerometer, gyroscope, and magnetometer/compass) Fourteen volunteers perform a standardized set of movements including 20 voluntary falls and 16 activates of daily living, resulting in a large dataset with 2520 trials. To reduce the computational complexity of training and testing the classifiers, Özdemir et al decided to focus on the raw data for each sensor in a 4 s time window around the point of peak total acceleration of the waist sensor, and then perform feature extraction and reduction.(Özdemir et al, 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: Özdemir, Ahmet Turan, and Billur Barshan. “Detecting Falls with Wearable Sensors Using Machine Learning Techniques.” Sensors (Basel, Switzerland) 14.6 (2014): 10691–10708. PMC. Web. 23 Apr. 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fall detection dataset of Chinese hospitals of old age patients comes from the Kaggle Competition \"Fall Detection Data from China\" (https://www.kaggle.com/pitasr/falldata). The data consists of over 10000 sample of activities with six attributes. The attributes includes time, sugar level (SL), EEG monitoring rate (EEG), blood pressure (BP), heart beat rate (HR), blood circulation (CIRCULATION)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For old people, this project will predict if that elder will fall or not in the situation based on time, sugar level, eeg noitorying rate, blood pressure, heart rate and blood circulation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) load dataset into a dataframe (df)\n",
    "\n",
    "2) define an OUTPUT_LABEL\n",
    "\n",
    "3) calculate the prevalence of the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load dataset into a dataframe named df\n",
    "import pandas as pd\n",
    "df = pd.read_csv('falldeteciton.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 16382\n",
      "   ACTIVITY     TIME        SL      EEG  BP   HR  CIRCLUATION\n",
      "0         3  4722.92   4019.64 -1600.00  13   79          317\n",
      "1         2  4059.12   2191.03 -1146.08  20   54          165\n",
      "2         2  4773.56   2787.99 -1263.38  46   67          224\n",
      "3         4  8271.27   9545.98 -2848.93  26  138          554\n",
      "4         4  7102.16  14148.80 -2381.15  85  120          809\n"
     ]
    }
   ],
   "source": [
    "#number of observation\n",
    "print('Number of samples:',len(df))\n",
    "#Sample Dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACTIVITY\n",
       "0    4608\n",
       "1     502\n",
       "2    2502\n",
       "3    3588\n",
       "4    3494\n",
       "5    1688\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size of each ACTIVITY\n",
    "df.groupby(\"ACTIVITY\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Activity column, 0- Standing 1- Walking 2- Sitting 3- Falling 4- Cramps 5- Running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column called OUTPUT_LABEL based on your data that is 0 for your negative class and 1 for your positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['OUTPUT_LABEL'] = (df.ACTIVITY == 3).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 3 indicates falling, in this project, we take 3 for positive class and other activities as negative classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTIVITY  OUTPUT_LABEL\n",
       "0         3             1\n",
       "1         2             0\n",
       "2         2             0\n",
       "3         4             0\n",
       "4         4             0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['ACTIVITY','OUTPUT_LABEL']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the prevalence of the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_prevalence(y_actual):\n",
    "    # this function calculates the prevalence of the positive class (label = 1)\n",
    "    return (sum(y_actual)/len(y_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prevalence of the positive class: 0.219\n"
     ]
    }
   ],
   "source": [
    "print('prevalence of the positive class: %.3f'%calc_prevalence(df['OUTPUT_LABEL'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all the observation, the precentage of elder people fall is 21.9%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly explore the columns and unique values of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>TIME</th>\n",
       "      <th>SL</th>\n",
       "      <th>EEG</th>\n",
       "      <th>BP</th>\n",
       "      <th>HR</th>\n",
       "      <th>CIRCLUATION</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4722.92</td>\n",
       "      <td>4019.64</td>\n",
       "      <td>-1600.00</td>\n",
       "      <td>13</td>\n",
       "      <td>79</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4059.12</td>\n",
       "      <td>2191.03</td>\n",
       "      <td>-1146.08</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4773.56</td>\n",
       "      <td>2787.99</td>\n",
       "      <td>-1263.38</td>\n",
       "      <td>46</td>\n",
       "      <td>67</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8271.27</td>\n",
       "      <td>9545.98</td>\n",
       "      <td>-2848.93</td>\n",
       "      <td>26</td>\n",
       "      <td>138</td>\n",
       "      <td>554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7102.16</td>\n",
       "      <td>14148.80</td>\n",
       "      <td>-2381.15</td>\n",
       "      <td>85</td>\n",
       "      <td>120</td>\n",
       "      <td>809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTIVITY     TIME        SL      EEG  BP   HR  CIRCLUATION  OUTPUT_LABEL\n",
       "0         3  4722.92   4019.64 -1600.00  13   79          317             1\n",
       "1         2  4059.12   2191.03 -1146.08  20   54          165             0\n",
       "2         2  4773.56   2787.99 -1263.38  46   67          224             0\n",
       "3         4  8271.27   9545.98 -2848.93  26  138          554             0\n",
       "4         4  7102.16  14148.80 -2381.15  85  120          809             0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore the columns\n",
    "#Dataset\n",
    "df[list(df.columns)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVITY\n",
      "[3 2 4 5 0 1]\n",
      "TIME: 16009 unique values\n",
      "SL: 16137 unique values\n",
      "EEG: 11225 unique values\n",
      "BP: 341 unique values\n",
      "HR: 652 unique values\n",
      "CIRCLUATION: 2234 unique values\n",
      "OUTPUT_LABEL\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "# for each column\n",
    "for c in list(df.columns):\n",
    "    \n",
    "    # get a list of unique values\n",
    "    n = df[c].unique()\n",
    "    \n",
    "    # if number of unique values is less than 30, print the values. Otherwise print the number of unique values\n",
    "    if len(n)<30:\n",
    "        print(c)\n",
    "        print(n)\n",
    "    else:\n",
    "        print(c + ': ' +str(len(n)) + ' unique values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "df[[\"ACTIVITY\"]].boxplot()\n",
    "plt.subplot(2,3,2)\n",
    "df[[\"TIME\"]].boxplot()\n",
    "plt.subplot(2,3,3)\n",
    "df[[\"SL\"]].boxplot()\n",
    "plt.subplot(2,3,4)\n",
    "df[[\"EEG\"]].boxplot()\n",
    "plt.subplot(2,3,5)\n",
    "df[[\"BP\"]].boxplot()\n",
    "plt.subplot(2,3,6)\n",
    "df[[\"HR\"]].boxplot()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the \"Fall detection dataset from China\", there are 7 coloumns: ACTIVITIES, TIME, SL, EEG, BP, HR, CIRCULATION. Each feature has high variance and many outliers.\n",
    "    - ACTIVITIES is an output label. \n",
    "    - TIME, SL, EEG, BP, HR, CIRCLUATION are numerical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering is a process of creating a new data frame according to the knowledge of the dataset that makes machine learning algorithms (models) work.\n",
    "\n",
    "In this project, there are only numerical datasets. Although these features are correlated with each other, but all these features will be used in the machine learning models later because they are related to the outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>SL</th>\n",
       "      <th>EEG</th>\n",
       "      <th>BP</th>\n",
       "      <th>HR</th>\n",
       "      <th>CIRCLUATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TIME</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843200</td>\n",
       "      <td>-0.048278</td>\n",
       "      <td>0.442334</td>\n",
       "      <td>0.973901</td>\n",
       "      <td>0.876956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SL</th>\n",
       "      <td>0.843200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.050946</td>\n",
       "      <td>0.401064</td>\n",
       "      <td>0.859408</td>\n",
       "      <td>0.978060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG</th>\n",
       "      <td>-0.048278</td>\n",
       "      <td>-0.050946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.049892</td>\n",
       "      <td>-0.050316</td>\n",
       "      <td>-0.050408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP</th>\n",
       "      <td>0.442334</td>\n",
       "      <td>0.401064</td>\n",
       "      <td>-0.049892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.469164</td>\n",
       "      <td>0.419356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>0.973901</td>\n",
       "      <td>0.859408</td>\n",
       "      <td>-0.050316</td>\n",
       "      <td>0.469164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIRCLUATION</th>\n",
       "      <td>0.876956</td>\n",
       "      <td>0.978060</td>\n",
       "      <td>-0.050408</td>\n",
       "      <td>0.419356</td>\n",
       "      <td>0.904160</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TIME        SL       EEG        BP        HR  CIRCLUATION\n",
       "TIME         1.000000  0.843200 -0.048278  0.442334  0.973901     0.876956\n",
       "SL           0.843200  1.000000 -0.050946  0.401064  0.859408     0.978060\n",
       "EEG         -0.048278 -0.050946  1.000000 -0.049892 -0.050316    -0.050408\n",
       "BP           0.442334  0.401064 -0.049892  1.000000  0.469164     0.419356\n",
       "HR           0.973901  0.859408 -0.050316  0.469164  1.000000     0.904160\n",
       "CIRCLUATION  0.876956  0.978060 -0.050408  0.419356  0.904160     1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cor = df[[\"TIME\",\"SL\",\"EEG\",\"BP\",\"HR\",\"CIRCLUATION\"]]\n",
    "df_cor.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SL has strong positive correlation with TIME\n",
    "\n",
    "HR has strong positive correlation with TIME\n",
    "\n",
    "CIRCLUATION has strong positive correlation with TIME\n",
    "\n",
    "HR has strong positive correlation with SL\n",
    "\n",
    "CIRCLUATION has strong positive correlation with SL\n",
    "\n",
    "CIRCLUATION has strong positive correlation with HR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 2: Make a new dataframe that only has the columns of interest. Double check that the columns used to define your OUTPUT_LABEL are not part of cols_input! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_num = [\"TIME\",\"SL\",\"EEG\",\"BP\",\"HR\",\"CIRCLUATION\"]\n",
    "cols_all_cat =[]\n",
    "cols_extra=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if there are any missing values in the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TIME           0\n",
       "SL             0\n",
       "EEG            0\n",
       "BP             0\n",
       "HR             0\n",
       "CIRCLUATION    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols_num].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 6\n",
      "Numerical Features: 6\n",
      "Categorical Features: 0\n",
      "Extra features: 0\n"
     ]
    }
   ],
   "source": [
    "print('Total number of features:', len(cols_num + cols_all_cat + cols_extra))\n",
    "print('Numerical Features:',len(cols_num))\n",
    "print('Categorical Features:',len(cols_all_cat))\n",
    "print('Extra features:',len(cols_extra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>SL</th>\n",
       "      <th>EEG</th>\n",
       "      <th>BP</th>\n",
       "      <th>HR</th>\n",
       "      <th>CIRCLUATION</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722.92</td>\n",
       "      <td>4019.64</td>\n",
       "      <td>-1600.00</td>\n",
       "      <td>13</td>\n",
       "      <td>79</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4059.12</td>\n",
       "      <td>2191.03</td>\n",
       "      <td>-1146.08</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4773.56</td>\n",
       "      <td>2787.99</td>\n",
       "      <td>-1263.38</td>\n",
       "      <td>46</td>\n",
       "      <td>67</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8271.27</td>\n",
       "      <td>9545.98</td>\n",
       "      <td>-2848.93</td>\n",
       "      <td>26</td>\n",
       "      <td>138</td>\n",
       "      <td>554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7102.16</td>\n",
       "      <td>14148.80</td>\n",
       "      <td>-2381.15</td>\n",
       "      <td>85</td>\n",
       "      <td>120</td>\n",
       "      <td>809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TIME        SL      EEG  BP   HR  CIRCLUATION  OUTPUT_LABEL\n",
       "0  4722.92   4019.64 -1600.00  13   79          317             1\n",
       "1  4059.12   2191.03 -1146.08  20   54          165             0\n",
       "2  4773.56   2787.99 -1263.38  46   67          224             0\n",
       "3  8271.27   9545.98 -2848.93  26  138          554             0\n",
       "4  7102.16  14148.80 -2381.15  85  120          809             0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_input = cols_num\n",
    "df_data = df[cols_input + ['OUTPUT_LABEL']]\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Training/Validation/Test Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training samples take 70% of the total sample and training samples are used to fit the data and test the internal validation. (train the model.) Validation samples take 15% of total sample and it is used to compare between different algorithm (improve the model) Test samples take 15% of total sample and it is predictive ability/test the external validation.\n",
    "\n",
    "The methdology is the following. I first shuffle the samples in order to avoid any order which might affect the modeling. And then I use `random_state` as a random number generator. Finally I used `sample` function in to separate the data into training, validation and test with proportion of 70%, 15% and 15% respectively as I described above and caocluate the prevalence for each small dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training (df_train_all), validation (df_valid) and test (df_test) set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle the samples\n",
    "df_data = df_data.sample(n = len(df_data), random_state = 42)\n",
    "df_data = df_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split size: 0.300\n"
     ]
    }
   ],
   "source": [
    "# Save 30% of the data as validation and test data \n",
    "df_valid_test=df_data.sample(frac=0.30,random_state=42)\n",
    "print('Split size: %.3f'%(len(df_valid_test)/len(df_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df_valid_test.sample(frac = 0.5, random_state = 42)\n",
    "df_valid = df_valid_test.drop(df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the rest of the data as training data\n",
    "df_train_all=df_data.drop(df_valid_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prevalence(n = 2458):0.216\n",
      "Valid prevalence(n = 2457):0.222\n",
      "Train all prevalence(n = 11467):0.219\n"
     ]
    }
   ],
   "source": [
    "# check the prevalence of each \n",
    "print('Test prevalence(n = %d):%.3f'%(len(df_test),calc_prevalence(df_test.OUTPUT_LABEL.values)))\n",
    "print('Valid prevalence(n = %d):%.3f'%(len(df_valid),calc_prevalence(df_valid.OUTPUT_LABEL.values)))\n",
    "print('Train all prevalence(n = %d):%.3f'%(len(df_train_all), calc_prevalence(df_train_all.OUTPUT_LABEL.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each dataset, the prevalence remain around 0.2.This means, there are 20% positive classes and 80% negative classes. Hence, we need to balance the data in order to give more weight to the positives and less weight to nagetive weight. To do so, we use data balance method. We first split the training data into positive and negative, and then merge the balanced data and shuffle the order of training samples. Such data balance will provide advantages that the training dataset has 0.5 prevalence which same as the what we set for threshold (the threshold setting is in the next section).there are many other method to realzie balance data. For example, downsampling. A trade off using data balance is that we need be aware the disadvantage of losing information. Moreover, some model is relatively not very sensitive to imbalanced data. For example, stochastic gradient bossting is less sensitive than random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all samples (n = 16382)\n"
     ]
    }
   ],
   "source": [
    "print('all samples (n = %d)'%len(df_data))\n",
    "assert len(df_data) == (len(df_test)+len(df_valid)+len(df_train_all)),'math didnt work'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train balanced prevalence(n = 5022):0.500\n"
     ]
    }
   ],
   "source": [
    "# split the training data into positive and negative\n",
    "rows_pos = df_train_all.OUTPUT_LABEL == 1\n",
    "df_train_pos = df_train_all.loc[rows_pos]\n",
    "df_train_neg = df_train_all.loc[~rows_pos]\n",
    "\n",
    "# merge the balanced data\n",
    "df_train = pd.concat([df_train_pos, df_train_neg.sample(n = len(df_train_pos), random_state = 42)],axis = 0)\n",
    "\n",
    "# shuffle the order of training samples \n",
    "df_train = df_train.sample(n = len(df_train), random_state = 42).reset_index(drop = True)\n",
    "\n",
    "print('Train balanced prevalence(n = %d):%.3f'%(len(df_train), calc_prevalence(df_train.OUTPUT_LABEL.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all 4 dataframes to csv and the cols_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_all.to_csv('df_train_all.csv',index=False)\n",
    "df_train.to_csv('df_train.csv',index=False)\n",
    "df_valid.to_csv('df_valid.csv',index=False)\n",
    "df_test.to_csv('df_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(cols_input, open('cols_input.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill any missing values with the mean value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_my_missing(df, df_mean, col2use):\n",
    "    # This function fills the missing values\n",
    "\n",
    "    # check the columns are present\n",
    "    for c in col2use:\n",
    "        assert c in df.columns, c + ' not in df'\n",
    "        assert c in df_mean.col.values, c+ 'not in df_mean'\n",
    "    \n",
    "    # replace the mean \n",
    "    for c in col2use:\n",
    "        mean_value = df_mean.loc[df_mean.col == c,'mean_val'].values[0]\n",
    "        df[c] = df[c].fillna(mean_value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mean = df_train_all[cols_input].mean(axis = 0)\n",
    "# save the means\n",
    "df_mean.to_csv('df_mean.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>mean_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TIME</td>\n",
       "      <td>10940.884639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SL</td>\n",
       "      <td>75105.824174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EEG</td>\n",
       "      <td>-5013.830946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BP</td>\n",
       "      <td>58.191768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HR</td>\n",
       "      <td>211.625098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    col      mean_val\n",
       "0  TIME  10940.884639\n",
       "1    SL  75105.824174\n",
       "2   EEG  -5013.830946\n",
       "3    BP     58.191768\n",
       "4    HR    211.625098"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the means so we know how to do it for the test data\n",
    "df_mean_in = pd.read_csv('df_mean.csv', names =['col','mean_val'])\n",
    "df_mean_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_all = fill_my_missing(df_train_all, df_mean_in, cols_input)\n",
    "df_train = fill_my_missing(df_train, df_mean_in, cols_input)\n",
    "df_valid = fill_my_missing(df_valid, df_mean_in, cols_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training All shapes: (11467, 6)\n",
      "Training shapes: (5022, 6) (5022,)\n",
      "Validation shapes: (2457, 6) (2457,)\n"
     ]
    }
   ],
   "source": [
    "# create the X and y matrices\n",
    "X_train = df_train[cols_input].values\n",
    "X_train_all = df_train_all[cols_input].values\n",
    "X_valid = df_valid[cols_input].values\n",
    "\n",
    "y_train = df_train['OUTPUT_LABEL'].values\n",
    "y_valid = df_valid['OUTPUT_LABEL'].values\n",
    "\n",
    "print('Training All shapes:',X_train_all.shape)\n",
    "print('Training shapes:',X_train.shape, y_train.shape)\n",
    "print('Validation shapes:',X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a scalar, save it, and scale the X matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler  = StandardScaler()\n",
    "scaler.fit(X_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalerfile = 'scaler.sav'\n",
    "pickle.dump(scaler, open(scalerfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load it back\n",
    "scaler = pickle.load(open(scalerfile, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform our data matrices\n",
    "X_train_tf = scaler.transform(X_train)\n",
    "X_valid_tf = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  train a few machine learning models and use a few techniques for optimizing them. We will then select the best model based on performance matrics on the validation set. I choose AUC as the performance metrics because it is independent from threshold and my project does not need business sense for example minimize true positive or false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    \n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print('prevalence:%.3f'%calc_prevalence(y_actual))\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we balanced our training data, let's set our threshold at 0.5 to label a predicted sample as positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K nearest neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN has the full name K nearest neighbors. It is used often in classification. For a given data point, according to the distance from k nearest neighbors to classify the value of the data point. There are many different distance method could be use in KNN. Also, the number of k would affect the result of using KNN. Hence, two important hyperparameters are k and distance method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 2: train a KNN and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=100, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors = 100)\n",
    "knn.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Training:\n",
      "AUC:0.767\n",
      "accuracy:0.693\n",
      "recall:0.783\n",
      "precision:0.664\n",
      "specificity:0.588\n",
      "prevalence:0.500\n",
      " \n",
      "Validation:\n",
      "AUC:0.746\n",
      "accuracy:0.610\n",
      "recall:0.780\n",
      "precision:0.337\n",
      "specificity:0.542\n",
      "prevalence:0.222\n",
      " \n"
     ]
    }
   ],
   "source": [
    "y_train_preds = knn.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = knn.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('KNN')\n",
    "print('Training:')\n",
    "knn_train_auc, knn_train_accuracy, knn_train_recall, \\\n",
    "    knn_train_precision, knn_train_specificity = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "knn_valid_auc, knn_valid_accuracy, knn_valid_recall, \\\n",
    "    knn_valid_precision, knn_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression measures the relatipnship between the categorical dependent variable and one or mor independent variables by estimating probabilities using a logistic function. It is very common to conduct binary  depenent variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a logistic regression and evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ginna/anaconda3/envs/aly_6020/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(random_state = 42)\n",
    "lr.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Training:\n",
      "AUC:0.625\n",
      "accuracy:0.583\n",
      "recall:0.573\n",
      "precision:0.584\n",
      "specificity:0.593\n",
      "prevalence:0.500\n",
      " \n",
      "Validation:\n",
      "AUC:0.601\n",
      "accuracy:0.576\n",
      "recall:0.548\n",
      "precision:0.273\n",
      "specificity:0.584\n",
      "prevalence:0.222\n",
      " \n"
     ]
    }
   ],
   "source": [
    "y_train_preds = lr.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = lr.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Logistic Regression')\n",
    "print('Training:')\n",
    "lr_train_auc, lr_train_accuracy, lr_train_recall, \\\n",
    "    lr_train_precision, lr_train_specificity = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic gradient descent is similar to gradient descent that both apply the iteration and the first-order differential to solve the optimization problems. However, the stochastic gradient descent only uses one piece of data in each iteration instead of using all of the data information. Therefore, the stochastic could help to reduce the calculation speed, but it may take more iterations to reach the optimum solutions for the stochastic data used in the iterations. In this algorithm, the learning rate is an important hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a stochastic gradient descent model and evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ginna/anaconda3/envs/aly_6020/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdc=SGDClassifier(loss = 'log',alpha = 0.1,random_state = 42)\n",
    "sgdc.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descend\n",
      "Training:\n",
      "AUC:0.588\n",
      "accuracy:0.543\n",
      "recall:0.696\n",
      "precision:0.533\n",
      "specificity:0.389\n",
      "prevalence:0.500\n",
      " \n",
      "Validation:\n",
      "AUC:0.563\n",
      "accuracy:0.451\n",
      "recall:0.685\n",
      "precision:0.241\n",
      "specificity:0.384\n",
      "prevalence:0.222\n",
      " \n"
     ]
    }
   ],
   "source": [
    "y_train_preds = sgdc.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = sgdc.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Stochastic Gradient Descend')\n",
    "print('Training:')\n",
    "sgdc_train_auc, sgdc_train_accuracy, sgdc_train_recall, sgdc_train_precision, sgdc_train_specificity =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "sgdc_valid_auc, sgdc_valid_accuracy, sgdc_valid_recall, sgdc_valid_precision, sgdc_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes model assumes that all the variables are independent. Thus, we could calculate the probability of the event given the other variables probabilities without trouble of multicollinearity. In this algorithm, we implement the Bayes theorem and the assumptions of the independence, therefore, we call it Naive Bayes. There are many different types of the probability distribution for the other variables like the normal distribution, Multinomial Naive Bayes or using Gaussian distribution as we used here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train naive bayes model and evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Training:\n",
      "AUC:0.580\n",
      "accuracy:0.525\n",
      "recall:0.838\n",
      "precision:0.516\n",
      "specificity:0.212\n",
      "prevalence:0.500\n",
      " \n",
      "Validation:\n",
      "AUC:0.544\n",
      "accuracy:0.338\n",
      "recall:0.813\n",
      "precision:0.225\n",
      "specificity:0.202\n",
      "prevalence:0.222\n",
      " \n"
     ]
    }
   ],
   "source": [
    "y_train_preds = nb.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = nb.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Naive Bayes')\n",
    "print('Training:')\n",
    "nb_train_auc, nb_train_accuracy, nb_train_recall, nb_train_precision, nb_train_specificity =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "nb_valid_auc, nb_valid_accuracy, nb_valid_recall, nb_valid_precision, nb_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree classifier use the concept of a tree-model. From a root question, each layer of leaves split the question into a binary question. For example, the root question, is this a male, with answer yes. The tree will go to the brunch of a male and ask next question. Each leaves represent class labels and brunches represent features with condinous condiction. Therefore, decision tree classifier at every layer select the one that gives best information gain and finalize the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train decision tree model and evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth = 10, random_state = 42)\n",
    "tree.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Training:\n",
      "AUC:0.931\n",
      "accuracy:0.850\n",
      "recall:0.922\n",
      "precision:0.807\n",
      "specificity:0.773\n",
      "prevalence:0.500\n",
      " \n",
      "Validation:\n",
      "AUC:0.813\n",
      "accuracy:0.718\n",
      "recall:0.841\n",
      "precision:0.431\n",
      "specificity:0.677\n",
      "prevalence:0.222\n",
      " \n"
     ]
    }
   ],
   "source": [
    "y_train_preds = tree.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = tree.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Decision Tree')\n",
    "print('Training:')\n",
    "tree_train_auc, tree_train_accuracy, tree_train_recall, tree_train_precision, tree_train_specificity =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "tree_valid_auc, tree_valid_accuracy, tree_valid_recall, tree_valid_precision, tree_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest is consist of many decision trees. Each decision tree selected subset of training set randomly. It aggregate the results from all decision trees to identity the final test classifier. One advantage of using random forest is that it is very fast to train. However, it take times to create predictions once trained. If we want to get more accurcy result, we need to have more trees and it consumes calculation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train random forest model and evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ginna/anaconda3/envs/aly_6020/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(max_depth = 6, random_state = 42)\n",
    "rf.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Training:\n",
      "AUC:0.847\n",
      "accuracy:0.774\n",
      "recall:0.871\n",
      "precision:0.730\n",
      "specificity:0.678\n",
      "prevalence:0.500\n",
      " \n",
      "Validation:\n",
      "AUC:0.811\n",
      "accuracy:0.683\n",
      "recall:0.852\n",
      "precision:0.400\n",
      "specificity:0.635\n",
      "prevalence:0.222\n",
      " \n"
     ]
    }
   ],
   "source": [
    "y_train_preds = rf.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = rf.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Random Forest')\n",
    "print('Training:')\n",
    "rf_train_auc, rf_train_accuracy, rf_train_recall, rf_train_precision, rf_train_specificity =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "rf_valid_auc, rf_valid_accuracy, rf_valid_recall, rf_valid_precision, rf_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient boosting classifier applies gradient boostin algorithms in decision tree models. By this method, a weak decision tree model could be improved in classification through iterations and the gradients. By each iteration, the loss function will decrease until it reaches the optimum solutions. Gradient descents are used to seek the best tree model in thsi algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train gradient boosting model and evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=1.0, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=42,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc =GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "     max_depth=3, random_state=42)\n",
    "gbc.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "Training:\n",
      "AUC:0.978\n",
      "accuracy:0.925\n",
      "recall:0.948\n",
      "precision:0.907\n",
      "specificity:0.902\n",
      "prevalence:0.500\n",
      " \n",
      "Validation:\n",
      "AUC:0.860\n",
      "accuracy:0.769\n",
      "recall:0.830\n",
      "precision:0.488\n",
      "specificity:0.751\n",
      "prevalence:0.222\n",
      " \n"
     ]
    }
   ],
   "source": [
    "y_train_preds = gbc.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = gbc.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Gradient Boosting Classifier')\n",
    "print('Training:')\n",
    "gbc_train_auc, gbc_train_accuracy, gbc_train_recall, gbc_train_precision, gbc_train_specificity = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "gbc_valid_auc, gbc_valid_accuracy, gbc_valid_recall, gbc_valid_precision, gbc_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a dataframe with these results and plot the outcomes using a package called seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_results = pd.DataFrame({'classifier':['KNN','KNN','LR','LR','SGD','SGD','NB','NB','DT','DT','RF','RF','GB','GB'],\n",
    "                           'data_set':['train','valid']*7,\n",
    "                          'auc':[knn_train_auc, knn_valid_auc,lr_train_auc,lr_valid_auc,sgdc_train_auc,sgdc_valid_auc,nb_train_auc,nb_valid_auc,tree_train_auc,tree_valid_auc,rf_train_auc,rf_valid_auc,gbc_train_auc,gbc_valid_auc,],\n",
    "                          'accuracy':[knn_train_accuracy, knn_valid_accuracy,lr_train_accuracy,lr_valid_accuracy,sgdc_train_accuracy,sgdc_valid_accuracy,nb_train_accuracy,nb_valid_accuracy,tree_train_accuracy,tree_valid_accuracy,rf_train_accuracy,rf_valid_accuracy,gbc_train_accuracy,gbc_valid_accuracy,],\n",
    "                          'recall':[knn_train_recall, knn_valid_recall,lr_train_recall,lr_valid_recall,sgdc_train_recall,sgdc_valid_recall,nb_train_recall,nb_valid_recall,tree_train_recall,tree_valid_recall,rf_train_recall,rf_valid_recall,gbc_train_recall,gbc_valid_recall,],\n",
    "                          'precision':[knn_train_precision, knn_valid_precision,lr_train_precision,lr_valid_precision,sgdc_train_precision,sgdc_valid_precision,nb_train_precision,nb_valid_precision,tree_train_precision,tree_valid_precision,rf_train_precision,rf_valid_precision,gbc_train_auc,gbc_valid_precision,],\n",
    "                          'specificity':[knn_train_specificity, knn_valid_specificity,lr_train_specificity,lr_valid_specificity,sgdc_train_specificity,sgdc_valid_specificity,nb_train_specificity,nb_valid_specificity,tree_train_specificity,tree_valid_specificity,rf_train_specificity,rf_valid_specificity,gbc_train_specificity,gbc_valid_specificity,]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>data_set</th>\n",
       "      <th>auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>train</td>\n",
       "      <td>0.767213</td>\n",
       "      <td>0.693349</td>\n",
       "      <td>0.782557</td>\n",
       "      <td>0.664076</td>\n",
       "      <td>0.587814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.746488</td>\n",
       "      <td>0.610094</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.337025</td>\n",
       "      <td>0.541601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>train</td>\n",
       "      <td>0.625055</td>\n",
       "      <td>0.582636</td>\n",
       "      <td>0.572680</td>\n",
       "      <td>0.584315</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.600956</td>\n",
       "      <td>0.575906</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.273309</td>\n",
       "      <td>0.583987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGD</td>\n",
       "      <td>train</td>\n",
       "      <td>0.588163</td>\n",
       "      <td>0.542613</td>\n",
       "      <td>0.695739</td>\n",
       "      <td>0.532622</td>\n",
       "      <td>0.389486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.562711</td>\n",
       "      <td>0.450549</td>\n",
       "      <td>0.684982</td>\n",
       "      <td>0.240979</td>\n",
       "      <td>0.383569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NB</td>\n",
       "      <td>train</td>\n",
       "      <td>0.580043</td>\n",
       "      <td>0.525289</td>\n",
       "      <td>0.838311</td>\n",
       "      <td>0.515552</td>\n",
       "      <td>0.212266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.544246</td>\n",
       "      <td>0.337810</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.225495</td>\n",
       "      <td>0.201988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>train</td>\n",
       "      <td>0.931202</td>\n",
       "      <td>0.850259</td>\n",
       "      <td>0.921545</td>\n",
       "      <td>0.806553</td>\n",
       "      <td>0.773397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.813360</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.840659</td>\n",
       "      <td>0.430986</td>\n",
       "      <td>0.676609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF</td>\n",
       "      <td>train</td>\n",
       "      <td>0.846657</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870569</td>\n",
       "      <td>0.729883</td>\n",
       "      <td>0.677818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.811145</td>\n",
       "      <td>0.682947</td>\n",
       "      <td>0.851648</td>\n",
       "      <td>0.399828</td>\n",
       "      <td>0.634746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GB</td>\n",
       "      <td>train</td>\n",
       "      <td>0.977994</td>\n",
       "      <td>0.925329</td>\n",
       "      <td>0.948228</td>\n",
       "      <td>0.977994</td>\n",
       "      <td>0.902429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GB</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.859927</td>\n",
       "      <td>0.768824</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.488147</td>\n",
       "      <td>0.751439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classifier data_set       auc  accuracy    recall  precision  specificity\n",
       "0         KNN    train  0.767213  0.693349  0.782557   0.664076     0.587814\n",
       "1         KNN    valid  0.746488  0.610094  0.780220   0.337025     0.541601\n",
       "2          LR    train  0.625055  0.582636  0.572680   0.584315     0.592593\n",
       "3          LR    valid  0.600956  0.575906  0.547619   0.273309     0.583987\n",
       "4         SGD    train  0.588163  0.542613  0.695739   0.532622     0.389486\n",
       "5         SGD    valid  0.562711  0.450549  0.684982   0.240979     0.383569\n",
       "6          NB    train  0.580043  0.525289  0.838311   0.515552     0.212266\n",
       "7          NB    valid  0.544246  0.337810  0.813187   0.225495     0.201988\n",
       "8          DT    train  0.931202  0.850259  0.921545   0.806553     0.773397\n",
       "9          DT    valid  0.813360  0.717949  0.840659   0.430986     0.676609\n",
       "10         RF    train  0.846657  0.774194  0.870569   0.729883     0.677818\n",
       "11         RF    valid  0.811145  0.682947  0.851648   0.399828     0.634746\n",
       "12         GB    train  0.977994  0.925329  0.948228   0.977994     0.902429\n",
       "13         GB    valid  0.859927  0.768824  0.829670   0.488147     0.751439"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick one performance metric that will use for picking the best model. Explain the choice of performance metric. Make a bar plot of this performance metric below to demonstrate the baseline performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC stands as the area under reciver operating characteristic. In this binary classification prediction problem, I scaled and normalized the dataset, and AUC indicates the probability that a classifier chosen randomly is in positive ranks higher than a classifier chosen randomly is in negative. In other words, AUC represent the measurement of distinguish between classes. The number of AUC indicates how much a model is capable to distinguish labels. Also, AUC is independent from threshold and there is no such requirement that I need to improve the true positive and false nagetive. Thus, I use AUC for picking the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.barplot(x=\"classifier\", y=\"auc\", hue=\"data_set\", data=df_results)\n",
    "ax.set_xlabel('Classifier',fontsize = 15)\n",
    "ax.set_ylabel('AUC', fontsize = 15)\n",
    "ax.tick_params(labelsize=15)\n",
    "\n",
    "# Put the legend out of the figure\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using  baseline model that has the best performance on the validation set, plot a learning curve for that model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring = 'roc_auc')\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"b\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"b\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "title = \"Learning Curves (Gradient Boosting Classifier)\"\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "estimator =GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=3, random_state=42)\n",
    "plot_learning_curve(estimator, title, X_train_tf, y_train, ylim=(0.2, 1.01), cv=cv, n_jobs=4)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify if your model has high variance or high bias. Briefly discuss what techniques could be used to improve performance of that model.  \n",
    "\n",
    "Because the Gradient Boosting model has the highest training AUC and it has a gap between training auc and validation auc, which indicates there is a chance to improve the model. Thus, I take GBC as the important baseline model. The learning curve of the Gradient Boosting model shows the training score is perfectly good, but there exists a large difference between the training and validation scores and is a sign of overfitting. The model has a high variance. To reduce the variance the following techniques would help reduce the variance.\n",
    "\n",
    "● Add more samples\n",
    "\n",
    "● Add regularization\n",
    "\n",
    "● Reduce number of features\n",
    "\n",
    "● Decrease model complexity\n",
    "\n",
    "● Add better features\n",
    "\n",
    "● Change model architecture\n",
    "\n",
    "As it is not possible to add more samples and add better features. I will choose from reducing the number of features, decrease model complexity change model architecture. However, all my data are numerical, I believe decrease model complexity and hyperparameter tuning would boost my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the feature importance for logistic regression and random forest models here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ginna/anaconda3/envs/aly_6020/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(random_state = 42)\n",
    "lr.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(lr.coef_[0],\n",
    "                                   index = cols_input,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EEG</th>\n",
       "      <td>5.244815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIRCLUATION</th>\n",
       "      <td>1.328998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME</th>\n",
       "      <td>1.132607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP</th>\n",
       "      <td>-0.299546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>-0.605028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SL</th>\n",
       "      <td>-1.520359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             importance\n",
       "EEG            5.244815\n",
       "CIRCLUATION    1.328998\n",
       "TIME           1.132607\n",
       "BP            -0.299546\n",
       "HR            -0.605028\n",
       "SL            -1.520359"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between five features, EEG has highest positive coefficients which is predictive of elder people fall and SL (Sugar level) has highest negative coefficients is predictive of elder people do not fall.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = np.min([50, len(cols_input)])\n",
    "ylocs = np.arange(num)\n",
    "# get the feature importance for top num and sort in reverse order\n",
    "values_to_plot = feature_importances.iloc[:num].values.ravel()[::-1]\n",
    "feature_labels = list(feature_importances.iloc[:num].index)[::-1]\n",
    "\n",
    "plt.figure(num=None, figsize=(20,9), dpi=80, facecolor='w', edgecolor='k');\n",
    "plt.barh(ylocs, values_to_plot, align = 'center')\n",
    "plt.ylabel('Features')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Positive Feature Importance Score - Logistic Regression')\n",
    "plt.yticks(ylocs, feature_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components providing positive influence are EEG, CIRCULATION and TIME. The component contributes the most positive influence is EEG with the value of 4.087166. The component providing negative influence are BP,HR and SL. The component contributes the most negative influence to elder people fall is SL with the value of -1.909831. Hence, EEG and SL are the top 2 impact in terms of the importance features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your best baseline model, pick a hyperparameter and show its effect for a range of values (similar to what we did for the random forest and max_depths in the diabetes project. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In setting up machine learning models, the essential is hyperparameter tuning. The hyperparameter tuning affects the performance of models. \n",
    "\n",
    "Because random forest moel and Gradient boosting has good performance. Here, I select a commone parameter in random forest tree model and Gradient boosting model `max_depth`. `max_depth` is the maximum depth of the tree, which means it controls the depth of the tree. I plotted the results of how the random forest and gradient boosting model perform in different `max_depth`, in other words, how `max_depth` affects the gradient boosting and random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model for each max_depth in a list. Store the auc for the training and validation set\n",
    "\n",
    "# max depths\n",
    "max_depths = np.arange(2,20,2)\n",
    "\n",
    "train_aucs = np.zeros(len(max_depths))\n",
    "valid_aucs = np.zeros(len(max_depths))\n",
    "\n",
    "for jj in range(len(max_depths)):\n",
    "    max_depth = max_depths[jj]\n",
    "\n",
    "    # fit model\n",
    "    gbc=GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=max_depth, random_state=42)\n",
    "    gbc.fit(X_train_tf, y_train)        \n",
    "    # get predictions\n",
    "    y_train_preds = gbc.predict_proba(X_train_tf)[:,1]\n",
    "    y_valid_preds = gbc.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "    # calculate auc\n",
    "    auc_train = roc_auc_score(y_train, y_train_preds)\n",
    "    auc_valid = roc_auc_score(y_valid, y_valid_preds)\n",
    "\n",
    "    # save aucs\n",
    "    train_aucs[jj] = auc_train\n",
    "    valid_aucs[jj] = auc_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(max_depths, train_aucs,'o-',label = 'train')\n",
    "plt.plot(max_depths, valid_aucs,'o-',label = 'valid')\n",
    "\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot, as we increase the `max_depth` the training and validation performance are improved until the max_depth reach 10. After the `max_depth` reach to 10, the validation performance decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train a model for each max_depth in a list. Store the auc for the training and validation set\n",
    "\n",
    "# max depths\n",
    "max_depths = np.arange(2,20,2)\n",
    "\n",
    "train_aucs = np.zeros(len(max_depths))\n",
    "valid_aucs = np.zeros(len(max_depths))\n",
    "\n",
    "for jj in range(len(max_depths)):\n",
    "    max_depth = max_depths[jj]\n",
    "\n",
    "    # fit model\n",
    "    rf=RandomForestClassifier(n_estimators = 100, max_depth = max_depth, random_state = 42)\n",
    "    rf.fit(X_train_tf, y_train)        \n",
    "    # get predictions\n",
    "    y_train_preds = rf.predict_proba(X_train_tf)[:,1]\n",
    "    y_valid_preds = rf.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "    # calculate auc\n",
    "    auc_train = roc_auc_score(y_train, y_train_preds)\n",
    "    auc_valid = roc_auc_score(y_valid, y_valid_preds)\n",
    "\n",
    "    # save aucs\n",
    "    train_aucs[jj] = auc_train\n",
    "    valid_aucs[jj] = auc_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(max_depths, train_aucs,'o-',label = 'train')\n",
    "plt.plot(max_depths, valid_aucs,'o-',label = 'valid')\n",
    "\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot, as we increase the `max_depth` the training and validation performance are improved. However, as the `max_depth` increase, the variance increase as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, hyperparameter affects the random forest model significantly. However, there are many hyperparameter, and it is no efficient and unscientific to try every hyperparameter with every value. To avoid such computationally intensive, I decided use random Search (RandomizedSearchCV), which randomly test a permutation of hyperparameters. This technique can optimizes the parameters automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using RandomizedSearchCV, optimize a few of your baseline models. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "auc_scoring = make_scorer(roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc =GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "     max_depth=3, random_state=42)\n",
    "gbc.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# number of trees\n",
    "n_estimators = range(50,200,50)\n",
    "\n",
    "# maximum depth of the tree\n",
    "max_depth = range(1,5,1)\n",
    "\n",
    "# learning rate\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "\n",
    "# random grid\n",
    "\n",
    "random_grid_gbc = {'n_estimators':n_estimators,\n",
    "              'max_depth':max_depth,\n",
    "              'learning_rate':learning_rate}\n",
    "\n",
    "# create the randomized search cross-validation\n",
    "gbc_random = RandomizedSearchCV(estimator = gbc, param_distributions = random_grid_gbc, n_iter = 20, cv = 2, scoring=auc_scoring,verbose = 0, random_state = 42)\n",
    "\n",
    "t1 = time.time()\n",
    "gbc_random.fit(X_train_tf, y_train)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = gbc.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = gbc.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "thresh = 0.5\n",
    "\n",
    "print('Baseline gbc')\n",
    "gbc_train_base_auc = roc_auc_score(y_train, y_train_preds)\n",
    "gbc_valid_base_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "\n",
    "print('Training AUC:%.3f'%(gbc_train_base_auc))\n",
    "print('Validation AUC:%.3f'%(gbc_valid_base_auc))\n",
    "print('Optimized gbc')\n",
    "y_train_preds_random = gbc_random.best_estimator_.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds_random = gbc_random.best_estimator_.predict_proba(X_valid_tf)[:,1]\n",
    "gbc_train_opt_auc = roc_auc_score(y_train, y_train_preds_random)\n",
    "gbc_valid_opt_auc = roc_auc_score(y_valid, y_valid_preds_random)\n",
    "\n",
    "print('Training AUC:%.3f'%(gbc_train_opt_auc))\n",
    "print('Validation AUC:%.3f'%(gbc_valid_opt_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of trees\n",
    "n_estimators = range(200,1000,200)\n",
    "# maximum number of features to use at each split\n",
    "max_features = ['auto','sqrt','log2']\n",
    "# maximum depth of the tree\n",
    "max_depth = range(2,20,2)\n",
    "# minimum number of samples to split a node\n",
    "min_samples_split = range(2,10,2)\n",
    "# criterion for evaluating a split\n",
    "criterion = ['gini','entropy']\n",
    "\n",
    "# random grid\n",
    "\n",
    "random_grid = {'n_estimators':n_estimators,\n",
    "              'max_features':max_features,\n",
    "              'max_depth':max_depth,\n",
    "              'min_samples_split':min_samples_split,\n",
    "              'criterion':criterion}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a baseline model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# create the randomized search cross-validation\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 20, cv = 2, \n",
    "                               scoring=auc_scoring,verbose = 1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# fit the random search model (this will take a few minutes)\n",
    "t1 = time.time()\n",
    "rf_random.fit(X_train_tf, y_train)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(max_depth = 6, random_state = 42)\n",
    "rf.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = rf.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = rf.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "thresh = 0.5\n",
    "\n",
    "print('Baseline Random Forest')\n",
    "rf_train_base_auc = roc_auc_score(y_train, y_train_preds)\n",
    "rf_valid_base_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "\n",
    "print('Training AUC:%.3f'%(rf_train_base_auc))\n",
    "print('Validation AUC:%.3f'%(rf_valid_base_auc))\n",
    "\n",
    "print('Optimized Random Forest')\n",
    "y_train_preds_random = rf_random.best_estimator_.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds_random = rf_random.best_estimator_.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "rf_train_opt_auc = roc_auc_score(y_train, y_train_preds_random)\n",
    "rf_valid_opt_auc = roc_auc_score(y_valid, y_valid_preds_random)\n",
    "\n",
    "print('Training AUC:%.3f'%(rf_train_opt_auc))\n",
    "print('Validation AUC:%.3f'%(rf_valid_opt_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot comparing the performance of the optimized models to the baseline models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({'classifier':['GB','GB','RF','RF'],\n",
    "                           'data_set':['baseline','optimized']*2,\n",
    "                          'auc':[gbc_valid_base_auc,gbc_valid_opt_auc,\n",
    "                                 rf_valid_base_auc,rf_valid_opt_auc\n",
    "                                 ],\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "ax = sns.barplot(x=\"classifier\", y=\"auc\", hue=\"data_set\", data=df_results)\n",
    "ax.set_xlabel('Classifier',fontsize = 15)\n",
    "ax.set_ylabel('AUC', fontsize = 15)\n",
    "ax.tick_params(labelsize=15)\n",
    "# Put the legend out of the figure\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({'classifier':['RF','RF','RF','RF','GB','GB','GB','GB'],\n",
    "                           'data_set':['train baseline','valid baseline','train optimized','valid optimized']*2,\n",
    "                          'auc':[\n",
    "                              rf_train_base_auc,rf_valid_base_auc,rf_train_opt_auc,rf_valid_opt_auc,\n",
    "                                 gbc_train_base_auc,gbc_valid_base_auc,gbc_train_opt_auc,gbc_valid_opt_auc\n",
    "                         ],\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "ax = sns.barplot(x=\"classifier\", y=\"auc\", hue=\"data_set\", data=df_results)\n",
    "ax.set_xlabel('Classifier',fontsize = 15)\n",
    "ax.set_ylabel('AUC', fontsize = 15)\n",
    "ax.tick_params(labelsize=15)\n",
    "# Put the legend out of the figure\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick your best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick your best model. Explain why I picked it. Save the model using pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({'classifier':['RF','RF','RF','RF'],\n",
    "                           'data_set':['train baseline','valid baseline','train optimized','valid optimized']*1,\n",
    "                          'auc':[\n",
    "                              \n",
    "                              rf_train_base_auc,rf_valid_base_auc,rf_train_opt_auc,rf_valid_opt_auc,\n",
    "                                 \n",
    "                         ],\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "ax = sns.barplot(x=\"classifier\", y=\"auc\", hue=\"data_set\", data=df_results)\n",
    "ax.set_xlabel('Classifier',fontsize = 15)\n",
    "ax.set_ylabel('AUC', fontsize = 15)\n",
    "ax.tick_params(labelsize=15)\n",
    "# Put the legend out of the figure\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has limited features, I decided to keep all features and try to optimize the model by hyperparameter tuning. In hyperparameter tuning, random forest it has the best performance in AUC, which is 0.916817 in validation dataset. From the above, the optimized trainging dataset has a huge improvement, so do validation dataset. This means, hyperparameter tunging optimized the result. Meanwhile, the optimized training dataset is close to 1 which also indicates some kind of overfitting in the training dataset. Hence, I believe, altough the gap between optimized trainning and validation is more than the gradient boosting model, random forest cam be improved using grid search.\n",
    "\n",
    "The hyperparameters for random forest are the following: \n",
    "\n",
    "{'n_estimators': 400,\n",
    " 'min_samples_split': 2,\n",
    " 'max_features': 'log2',\n",
    " 'max_depth': 18,\n",
    " 'criterion': 'entropy'}\n",
    " \n",
    " Then I save the result into pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(rf_random.best_estimator_, open('best_rf_classifier.pkl', 'wb'),protocol = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 4: STOP HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rvaluate the performance of the best model on the training, validation and test sets. Make an ROC curve too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model, columns, mean values, and scaler\n",
    "best_model = pickle.load(open('best_rf_classifier.pkl','rb'))\n",
    "cols_input = pickle.load(open('cols_input.sav','rb'))\n",
    "df_mean_in = pd.read_csv('df_mean.csv', names =['col','mean_val'])\n",
    "scaler = pickle.load(open('scaler.sav', 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_train = pd.read_csv('df_train.csv')\n",
    "df_valid= pd.read_csv('df_valid.csv')\n",
    "df_test= pd.read_csv('df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill missing\n",
    "df_train = fill_my_missing(df_train, df_mean_in, cols_input)\n",
    "df_valid = fill_my_missing(df_valid, df_mean_in, cols_input)\n",
    "df_test = fill_my_missing(df_test, df_mean_in, cols_input)\n",
    "\n",
    "# create X and y matrices\n",
    "X_train = df_train[cols_input].values\n",
    "X_valid = df_valid[cols_input].values\n",
    "X_test = df_test[cols_input].values\n",
    "\n",
    "y_train = df_train['OUTPUT_LABEL'].values\n",
    "y_valid = df_valid['OUTPUT_LABEL'].values\n",
    "y_test = df_test['OUTPUT_LABEL'].values\n",
    "\n",
    "# transform our data matrices \n",
    "X_train_tf = scaler.transform(X_train)\n",
    "X_valid_tf = scaler.transform(X_valid)\n",
    "X_test_tf = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_preds = best_model.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = best_model.predict_proba(X_valid_tf)[:,1]\n",
    "y_test_preds = best_model.predict_proba(X_test_tf)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5\n",
    "\n",
    "print('Training:')\n",
    "train_auc, train_accuracy, train_recall, train_precision, train_specificity = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "valid_auc, valid_accuracy, valid_recall, valid_precision, valid_specificity = print_report(y_valid,y_valid_preds, thresh)\n",
    "print('Test:')\n",
    "test_auc, test_accuracy, test_recall, test_precision, test_specificity = print_report(y_test,y_test_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve \n",
    "\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_train_preds)\n",
    "auc_train = roc_auc_score(y_train, y_train_preds)\n",
    "\n",
    "fpr_valid, tpr_valid, thresholds_valid = roc_curve(y_valid, y_valid_preds)\n",
    "auc_valid = roc_auc_score(y_valid, y_valid_preds)\n",
    "\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_preds)\n",
    "auc_test = roc_auc_score(y_test, y_test_preds)\n",
    "\n",
    "plt.plot(fpr_train, tpr_train, 'r-',label ='Train AUC:%.3f'%auc_train)\n",
    "plt.plot(fpr_valid, tpr_valid, 'b-',label ='Valid AUC:%.3f'%auc_valid)\n",
    "plt.plot(fpr_test, tpr_test, 'g-',label ='Test AUC:%.3f'%auc_test)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there exist overfitting in the training dataset, the auc of test dataset matches the auc of the validation set. This model performs best in reducing overfitting and underfitting. With this model, we can use it to predict in what situation an elder people will fall and use it the aware doctors or nurse to prevent elder people from dieases. Moreover, such prediction has 81.3% accuracy. Then we are 2.4 times better than a random guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONGRATS! You got to the end!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "aly_6020",
   "language": "python",
   "name": "aly_6020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
